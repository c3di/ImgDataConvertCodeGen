{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d69784d-b95f-4f3a-9102-93281d6ab35e",
   "metadata": {},
   "source": [
    "# Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46698f-9b95-4771-9a6f-e253c59087c1",
   "metadata": {},
   "source": [
    "## Get Conversion Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d70ba4-b31e-4c84-a365-5561a800f93b",
   "metadata": {},
   "source": [
    "**When metadata as input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e2176d-a7be-4900-b23a-5f506787af34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The imports code is: \n",
      "import torch\n",
      "\n",
      "The conversion code is: \n",
      "var_af065e5b09c04bbeaf334306e17b3f79 = torch.from_numpy(input)\n",
      "var_fd0c641b704b4b748c58fbe8e281b6a8 = var_af065e5b09c04bbeaf334306e17b3f79.permute(2, 0, 1)\n",
      "output = torch.unsqueeze(var_fd0c641b704b4b748c58fbe8e281b6a8, 0)\n"
     ]
    }
   ],
   "source": [
    "from src.imgdataconvertcodegen import (get_conversion, get_convert_path,\n",
    "                                       add_image_metadata, add_convert_code_factory,\n",
    "                                       add_new_lib_preset)\n",
    "\n",
    "source_metadata = {\n",
    "    \"data_representation\": \"numpy.ndarray\",\n",
    "    \"color_channel\": \"rgb\",\n",
    "    \"channel_order\": \"channel last\",\n",
    "    \"minibatch_input\": False,\n",
    "    \"data_type\": \"uint8\",\n",
    "    \"intensity_range\": \"full\",\n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "target_metadata = {\n",
    "    \"data_representation\": \"torch.tensor\",\n",
    "    \"color_channel\": \"rgb\",\n",
    "    \"channel_order\": \"channel first\",\n",
    "    \"minibatch_input\": True,\n",
    "    \"data_type\": \"uint8\",\n",
    "    \"intensity_range\": \"full\",\n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "\n",
    "conversion = get_conversion(\"input\", source_metadata, \"output\", target_metadata)\n",
    "\n",
    "print(f\"The imports code is: \\n{conversion[0]}\\n\")\n",
    "print(f\"The conversion code is: \\n{conversion[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb064c3a-d861-400d-b4c2-065eabbb8005",
   "metadata": {},
   "source": [
    "**When library name as input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e13516-7a90-4820-a8c2-d508f7b825de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The imports code is: \n",
      "import torch\n",
      "\n",
      "The conversion code is: \n",
      "var_af065e5b09c04bbeaf334306e17b3f79 = torch.from_numpy(input)\n",
      "var_fd0c641b704b4b748c58fbe8e281b6a8 = var_af065e5b09c04bbeaf334306e17b3f79.permute(2, 0, 1)\n",
      "output = torch.unsqueeze(var_fd0c641b704b4b748c58fbe8e281b6a8, 0)\n"
     ]
    }
   ],
   "source": [
    "code_using_lib_name = get_conversion(\"input\", 'scikit-image', \"output\", 'torch', 'color', 'color')\n",
    "\n",
    "print(f\"The imports code is: \\n{conversion[0]}\\n\")\n",
    "print(f\"The conversion code is: \\n{conversion[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a715dbb1-9c08-4e2c-ac8b-f9b383ade3b0",
   "metadata": {},
   "source": [
    "## Get Conversion Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5890207c-e7b6-45f6-94f3-1191fba61a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the path is:\n",
      "\t{'data_representation': 'numpy.ndarray', 'color_channel': 'rgb', 'channel_order': 'channel last', 'minibatch_input': False, 'data_type': 'uint8', 'intensity_range': 'full', 'device': 'cpu'}\n",
      "\t{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel last', 'minibatch_input': False, 'data_type': 'uint8', 'intensity_range': 'full', 'device': 'cpu'}\n",
      "\t{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel first', 'minibatch_input': False, 'data_type': 'uint8', 'intensity_range': 'full', 'device': 'cpu'}\n",
      "\t{'data_representation': 'torch.tensor', 'color_channel': 'rgb', 'channel_order': 'channel first', 'minibatch_input': True, 'data_type': 'uint8', 'intensity_range': 'full', 'device': 'cpu'}\n"
     ]
    }
   ],
   "source": [
    "path = get_convert_path(source_metadata, target_metadata)\n",
    "\n",
    "print(\"the path is:\")\n",
    "for metadata in path:\n",
    "    print(f'\\t{metadata}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac21055-324e-4178-bdfc-aaaa985c436e",
   "metadata": {},
   "source": [
    "## Convert Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7395fa-08fe-41c3-978e-6947b8b142b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "source_image = np.random.randint(0, 256, (20, 20, 3), dtype=np.uint8)\n",
    "expected_image = torch.from_numpy(source_image).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "code = get_conversion(\"source_image\", source_metadata, \"actual_image\", target_metadata)\n",
    "exec(code[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30274281-cb66-4073-bb7f-fb8be9ff46aa",
   "metadata": {},
   "source": [
    "## Add new Metadata spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07115141-de31-4155-9db5-b9b87e89cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_image_metadata({\n",
    "    \"data_representation\": \"PIL.Image\",\n",
    "    \"color_channel\": \"rgb\",\n",
    "    \"channel_order\": \"channel last\",\n",
    "    \"minibatch_input\": False,\n",
    "    \"data_type\": \"uint8\",\n",
    "    \"intensity_range\": \"0to255\",\n",
    "    \"device\": \"cpu\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0b659-40b4-4d76-8309-90d50eeae0a0",
   "metadata": {},
   "source": [
    "## Add a new factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b6d83b5-fbc1-46c0-a5bd-6e6f6694c14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_torch_to_numpy(source, target):\n",
    "    if source[\"data_representation\"] == \"torch.tensor\" and target[\"data_representation\"] == \"numpy.ndarray\":\n",
    "        return '', f\"actual_image = source_image.numpy()\"\n",
    "    return None\n",
    "\n",
    "\n",
    "add_convert_code_factory(convert_torch_to_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8954afc-587a-4e14-8755-adba3df9f207",
   "metadata": {},
   "source": [
    "## Add a new librariy metadata preset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a98bea-9af7-45a0-8ba6-b1b63f4ce83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_new_lib_preset(\"PIL.image\", 'color', {\n",
    "    \"data_representation\": \"PIL.Image\",\n",
    "    \"color_channel\": \"rgb\",\n",
    "    \"channel_order\": \"channel last\",\n",
    "    \"minibatch_input\": False,\n",
    "    \"data_type\": \"uint8\",\n",
    "    \"intensity_range\": \"full\",\n",
    "    \"device\": \"cpu\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
