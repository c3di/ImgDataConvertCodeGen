{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a39ba89-0351-43ac-ad19-d69fed66aa2b",
   "metadata": {},
   "source": [
    "# Profiling Generating Conversion Code for In-memory Representations of Images using a Knowledge Graph of Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1275118e-0111-4669-8e2f-c8d750b9bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "from imgdataconvertcodegen import get_conversion, _code_generator\n",
    "\n",
    "def clear_cache_in_code_generator():\n",
    "    _code_generator._cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c0bcd9e-bea3-496f-9048-db58762babd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2275 function calls in 0.002 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 63 to 2 due to restriction <2>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.002    0.002 C:\\Users\\fech01-admin\\anaconda3\\envs\\kg4idr\\Lib\\site-packages\\networkx\\algorithms\\shortest_paths\\astar.py:12(astar_path)\n",
      "      694    0.000    0.000    0.000    0.000 C:\\Users\\fech01-admin\\anaconda3\\envs\\kg4idr\\Lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:78(<lambda>)\n",
      "\n",
      "\n",
      "Converson code is \n",
      "import torch\n",
      "var_b11f9ff02c5349818816742c66433c5f = torch.from_numpy(source_image)\n",
      "var_a288c0aa032f4feba081672859211321 = var_b11f9ff02c5349818816742c66433c5f.permute(2, 0, 1)\n",
      "target_image = var_a288c0aa032f4feba081672859211321.unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "\n",
    "clear_cache_in_code_generator()\n",
    "\n",
    "with cProfile.Profile() as profile:\n",
    "    source_image_desc = {\"lib\": \"numpy\"}\n",
    "    target_image_desc = {\"lib\": \"torch\", \"image_dtype\": 'uint8'}\n",
    "    code = get_conversion(\"source_image\", source_image_desc, \"target_image\", target_image_desc)\n",
    "    \n",
    "    \n",
    "    results = pstats.Stats(profile)\n",
    "    results.sort_stats(pstats.SortKey.TIME)\n",
    "    results.print_stats(2)\n",
    "\n",
    "    print(f'Converson code is \\n{code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de7f8b36-ad5b-451c-8a65-ff04fdc6efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         2338 function calls (2335 primitive calls) in 0.002 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 99 to 2 due to restriction <2>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.001    0.001    0.001    0.001 C:\\Users\\fech01-admin\\anaconda3\\envs\\kg4idr\\Lib\\site-packages\\networkx\\algorithms\\shortest_paths\\astar.py:12(astar_path)\n",
      "      694    0.000    0.000    0.000    0.000 C:\\Users\\fech01-admin\\anaconda3\\envs\\kg4idr\\Lib\\site-packages\\networkx\\algorithms\\shortest_paths\\weighted.py:78(<lambda>)\n",
      "\n",
      "\n",
      "Converson code is \n",
      "import torch\n",
      "var_374990e8cfea4fe48b00868dd22841d8 = torch.from_numpy(source_image)\n",
      "var_d1b3f9be8b5b45349e4f2a50faefe042 = var_374990e8cfea4fe48b00868dd22841d8.permute(2, 0, 1)\n",
      "actual_image = var_d1b3f9be8b5b45349e4f2a50faefe042.unsqueeze(0)\n",
      "\n",
      "The actual image matches the expected image.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "clear_cache_in_code_generator()\n",
    "with cProfile.Profile() as profile:\n",
    "    source_image = np.random.randint(0, 256, (20, 20, 3), dtype=np.uint8)\n",
    "    source_image_desc = {\"lib\": \"numpy\"}\n",
    "    target_image_desc = {\"lib\": \"torch\", \"image_dtype\": 'uint8'}\n",
    "    code = get_conversion(\"source_image\", source_image_desc, \"actual_image\", target_image_desc)\n",
    "    exec(code, globals())\n",
    "\n",
    "    results = pstats.Stats(profile)\n",
    "    results.sort_stats(pstats.SortKey.TIME)\n",
    "    results.print_stats(2)\n",
    "\n",
    "    print(f'Converson code is \\n{code}')\n",
    "    expected_image = torch.from_numpy(source_image).unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    assert torch.equal(actual_image, expected_image), \"The actual image does not match the expected image.\"\n",
    "    print(\"\\nThe actual image matches the expected image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56619076-6ad4-4ab4-8dca-332bbcbdb726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
